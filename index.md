---
layout: default
---

I am a post-doc at [Neural Dynamics of Visual Cognition lab](https://www.ewi-psy.fu-berlin.de/en/psychologie/arbeitsbereiche/neural_dyn_of_vis_cog/team_v2/index.html), department of Education and Psychology, Freie Universität Berlin. I am founded by the [Alexander von Humboldt Foundation](https://www.humboldt-foundation.de/en/).

I received my Ph.D. degree at the Department of Psychology, Tsinghua University in June 2022, collaborating with [Dan Zhang](https://www.psych.tsinghua.edu.cn/info/1180/1431.htm). 

The relationship between **the language and the thoughts** intrigues me a lot. This inspiration can be traced back to [Wilhelm von Humboldt](https://www.hu-berlin.de/en/about/history/wilh_html), a renowned German scholar. I first read Humboldt's (and a lot of other German scholars') books when I was at Hangzhou Foreign Languages School (a high school). I once considered studying literature to convey language studies. However, I now use a neuroscience approach, combining it with computational models, to investigate this question. Life is like a box of chocolates.

Please refer to my [CV](https://drive.google.com/file/d/1Yyk6CYIExn6Jys8v9KFVx1ONrUQFUpR1/view?usp=share_link) for further information.

In addition to science, I enjoy running and listening to various types of music, especially progressive rock. I am a former [saber fencer](https://mp.weixin.qq.com/s/TAolUNDpR2LE_un9fbIR6A) who once was a second-runner in the national college fencing competition. Currently, I am addicted to German literature and am trying to learn some German.

# Current Project

I am currently working with [Radoslaw Martin Cichy](http://userpage.fu-berlin.de/rmcichy/) and investgatng the **cross-modality semantic representations**.
So, what is cross-modality semantic representation? Imagine when you were a child, your caregivers may have read you stories before you went to bed. The adult was reading the story, and you as the child were listening. While the sensory input for you and the caregiver was different (visual vs. auditory), you and the storyteller would have arrived at a related comprehension of the story. It means that our brain could extract similar meaning albeit from different modalities. This is fascinating - how does our brain translate the information received from different modalities (visual vs. auditory) into similar comprehension and what are the neural mechanisms behind that? This question forms the core of my scientific interest. To answer it, I use the high temporal resolution EEG-recording methods, as well as the encoding models and deep neural networks.


# Publication

(#: co-first author, *: corresponding author)


## Peer Reviewed Publication

**Li, J.**, Hong, B., Nolte, G., Engel, A. K., & Zhang, D*. (2023).EEG-based speaker–listener neural coupling reflectsspeech-selective attentional mechanisms beyond the speech stimulus. _Cerebral Cortex_.

Zhang, X., **Li, J.**, Li, Z., HONG, B., Diao, T., Ma, X., ... & Zhang, D. (2023). Leading and Following: Noise Differently Affects Semantic and Acoustic Processing during Naturalistic Speech Comprehension. _NeuroImage_.

**Li, J.**, Hong, B., Nolte, G., Engel, A. K., & Zhang, D.* (2022). Preparatory delta phase response is correlated with naturalistic speech comprehension performance. _Cognitive Neurodynamics, 16_(2), 337–352. 

Li, Z. #,**Li, J.#**, Hong, B., Nolte, G., Engel, A. K., & Zhang, D.* (2021). Speaker-listener neural coupling reveals an adaptive mechanism for speech comprehension in a noisy environment. _Cerebral Cortex, 31_(10), 4719-4729.

Ding, Y., Hu, X., **Li, J.**, Ye, J., Wang, F., & Zhang, D. (2018). What makes a champion: the behavioral and neural correlates of expertise in multiplayer online battle arena games. _International Journal of Human–Computer Interaction, 34_(8), 682-694.

张丹, & **李佳蔚**. (2017). 探索思维的力量: 脑机接口研究现状与展望. _科技导报, 35_(9), 62-67.

